# ğŸ¤– Streamware Jetson - Lokalny Asystent Wizyjno-GÅ‚osowy

**Real-time audio/video AI assistant dla NVIDIA Jetson Orin Nano 8GB**

## ğŸ¯ FunkcjonalnoÅ›ci

- **Speech-to-Text**: Rozpoznawanie mowy w czasie rzeczywistym (PL/EN)
- **Vision AI**: Detekcja obiektÃ³w przez kamerÄ™
- **LLM**: Lokalne przetwarzanie jÄ™zyka naturalnego
- **Text-to-Speech**: Synteza mowy w jÄ™zyku polskim
- **Zero nagrywania**: Wszystko w RAM, zgodnoÅ›Ä‡ z RODO

## ğŸ“Š Architektura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mikrofon   â”‚â”€â”€â”€â”€â–ºâ”‚  STT        â”‚
â”‚  (PyAudio)  â”‚     â”‚  (Whisper)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kamera     â”‚â”€â”€â”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¤  Orchestratorâ”‚â”€â”€â”€â”€â–ºâ”‚  TTS        â”‚
â”‚  (OpenCV)   â”‚     â”‚             â”‚  (Asyncio)   â”‚     â”‚  (Piper)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚            â”‚                    â”‚
       â–¼            â”‚                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vision     â”‚â”€â”€â”€â”€â”€â”˜             â”‚  LLM        â”‚
â”‚  (YOLOv8)   â”‚                   â”‚  (Ollama)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Stack technologiczny

| Komponent | Technologia | Uzasadnienie |
|-----------|-------------|--------------|
| STT | **Faster-Whisper small** | Optymalny balans prÄ™dkoÅ›Ä‡/jakoÅ›Ä‡ na GPU |
| Vision | **YOLOv8n + TensorRT** | Natywna akceleracja Jetson |
| LLM | **Ollama + Phi-3 Mini** | 3.8B parametrÃ³w, mieÅ›ci siÄ™ w 8GB |
| TTS | **Piper TTS** | Ultra-lekki, dobra jakoÅ›Ä‡ PL |
| Audio I/O | **PyAudio + sounddevice** | Niskie latency |
| Video I/O | **OpenCV + GStreamer** | Hardware decode na Jetson |
| IPC | **asyncio + queues** | Zero overhead, single process |

## ğŸ“‹ Wymagania

### Hardware
- NVIDIA Jetson Orin Nano 8GB
- Mikrofon USB (lub I2S)
- Kamera USB/CSI
- GÅ‚oÅ›nik/sÅ‚uchawki

### Software
- JetPack 6.0+ (Ubuntu 22.04)
- CUDA 12.2+
- Python 3.10+

## ğŸš€ Instalacja

### 1. Przygotowanie systemu

```bash
# Aktualizacja
sudo apt update && sudo apt upgrade -y

# Podstawowe zaleÅ¼noÅ›ci
sudo apt install -y \
    python3-pip python3-venv \
    portaudio19-dev libsndfile1 \
    libopencv-dev ffmpeg \
    espeak-ng libespeak-ng-dev
```

### 2. Klonowanie i setup

```bash
git clone https://github.com/softreck/streamware-jetson.git
cd streamware-jetson

# Virtual environment
python3 -m venv venv
source venv/bin/activate

# Instalacja zaleÅ¼noÅ›ci
pip install -r requirements.txt
```

### 3. Modele

```bash
# Ollama
curl -fsSL https://ollama.com/install.sh | sh
ollama pull phi3:mini

# Whisper
python -c "from faster_whisper import WhisperModel; WhisperModel('small', device='cuda')"

# Piper TTS (polski gÅ‚os)
./scripts/download_piper_pl.sh

# YOLOv8 TensorRT
python scripts/export_yolo_tensorrt.py
```

### 4. Uruchomienie

```bash
python main.py
```

## ğŸ“ Struktura projektu

```
streamware-jetson/
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ requirements.txt        # ZaleÅ¼noÅ›ci Python
â”œâ”€â”€ config.yaml            # Konfiguracja
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py    # GÅ‚Ã³wna logika
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ stt.py         # Speech-to-Text
â”‚   â”‚   â””â”€â”€ tts.py         # Text-to-Speech
â”‚   â”œâ”€â”€ vision/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ detector.py    # Detekcja obiektÃ³w
â”‚   â””â”€â”€ llm/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ inference.py   # LLM wrapper
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ whisper/           # Faster-Whisper
â”‚   â”œâ”€â”€ yolo/              # YOLOv8 TensorRT
â”‚   â””â”€â”€ piper/             # Piper TTS
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_piper_pl.sh
â”‚   â”œâ”€â”€ export_yolo_tensorrt.py
â”‚   â””â”€â”€ benchmark.py
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_stt.py
    â”œâ”€â”€ test_vision.py
    â””â”€â”€ test_tts.py
```

## âš™ï¸ Konfiguracja

```yaml
# config.yaml
audio:
  sample_rate: 16000
  channels: 1
  chunk_size: 1024
  vad_threshold: 0.5

stt:
  model: "small"
  language: "pl"
  beam_size: 5
  compute_type: "float16"

vision:
  model: "yolov8n"
  confidence: 0.5
  process_every_n_frames: 5
  resolution: [640, 480]

llm:
  model: "phi3:mini"
  temperature: 0.7
  max_tokens: 256
  system_prompt: |
    JesteÅ› pomocnym asystentem wizyjno-gÅ‚osowym.
    Odpowiadasz krÃ³tko i konkretnie po polsku.
    Masz dostÄ™p do informacji o obiektach widzianych przez kamerÄ™.

tts:
  model: "pl_PL-gosia-medium"
  speaker_id: 0
  length_scale: 1.0
```

## ğŸ® UÅ¼ycie

### Podstawowe komendy gÅ‚osowe

| Komenda | DziaÅ‚anie |
|---------|-----------|
| "Co widzisz?" | Opis obiektÃ³w w polu widzenia |
| "Ile jest [obiektÃ³w]?" | Zliczanie obiektÃ³w danego typu |
| "Gdzie jest [obiekt]?" | Lokalizacja obiektu w kadrze |
| "Opisz scenÄ™" | PeÅ‚ny opis widzianej sceny |
| "Stop" / "Koniec" | ZakoÅ„czenie sesji |

### API (opcjonalne)

```python
from streamware import Assistant

assistant = Assistant(config="config.yaml")
assistant.start()

# Programowe zapytanie
response = assistant.query(
    text="Co leÅ¼y na stole?",
    include_vision=True
)
print(response)
```

## ğŸ“ˆ WydajnoÅ›Ä‡

| Metryka | WartoÅ›Ä‡ |
|---------|---------|
| Latency STT | ~200ms |
| Latency Vision | ~50ms (co 5 klatek) |
| Latency LLM | ~300-500ms |
| **Total latency** | **~600-900ms** |
| RAM usage | ~5-6GB |
| GPU usage | ~70-80% |

## ğŸ”Œ Rozszerzenia

### Dodanie bufora (z nagrywaniem)

```python
# config.yaml
buffer:
  enabled: true
  audio_seconds: 30
  video_frames: 150  # 5s @ 30fps
```

### Integracja z Home Assistant

```yaml
# home_assistant.yaml
homeassistant:
  enabled: true
  url: "http://192.168.1.100:8123"
  token: "${HA_TOKEN}"
```

### WebSocket API

```yaml
api:
  enabled: true
  host: "0.0.0.0"
  port: 8765
```

## ğŸ› Troubleshooting

### Problem: Brak dÅºwiÄ™ku z mikrofonu

```bash
# SprawdÅº urzÄ…dzenia
arecord -l
# Ustaw domyÅ›lne
export AUDIODEV=hw:1,0
```

### Problem: CUDA out of memory

```bash
# Zmniejsz model whisper
stt:
  model: "tiny"  # zamiast "small"
```

### Problem: Niska jakoÅ›Ä‡ TTS

```bash
# UÅ¼yj lepszego gÅ‚osu
./scripts/download_piper_pl.sh --quality high
```

## ğŸ“„ Licencja

MIT License - uÅ¼ywaj dowolnie w projektach komercyjnych i niekomercyjnych.

## ğŸ¤ WspÃ³Å‚praca

Projekt rozwijany przez [Softreck](https://softreck.com) w ramach [prototypowanie.pl](https://prototypowanie.pl).

Issues i PR-y mile widziane!
